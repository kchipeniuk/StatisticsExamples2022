{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc95f13",
   "metadata": {},
   "source": [
    "<h2> Exercise 4 - Hypothesis Testing </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd5dcc",
   "metadata": {},
   "source": [
    "We will now use the specifications in the previous example and consider the hypothesis $H_0:\\ \\beta_1\\neq 0$.  This time I'll use a $\\Gamma$ distribution for $x$, which is a distribution commonly used to model waiting times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "585beaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter estimate: [1.6554755458805437, -1.9628330664975442, 3.5642814931247035]\n"
     ]
    }
   ],
   "source": [
    "using Distributions\n",
    "using PyPlot\n",
    "using LinearAlgebra\n",
    "using Printf\n",
    "using Random\n",
    "\n",
    "Random.seed!(14389)\n",
    "\n",
    "d = Normal(0,1);\n",
    "N = 50;\n",
    "\n",
    "alpha = 1.7;\n",
    "beta1 = -2.0;\n",
    "beta2 = 3.4;\n",
    "\n",
    "x1 = rand(d,N);\n",
    "x2 = rand(d,N);\n",
    "eps = rand(Normal(0.0,5.0),N); # rand(TDist(5),N);\n",
    "\n",
    "y = alpha .+ beta1*x1 + beta2*x2 + eps;\n",
    "\n",
    "X = [ones(N) x1 x2];\n",
    "\n",
    "betaHat = (X'*X)\\(X'*y);\n",
    "\n",
    "println(\"Parameter estimate: \", betaHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db4a85",
   "metadata": {},
   "source": [
    "We now need to estimate the variance-covariance matrix $\\Sigma$ of $(\\widehat{\\alpha},\\widehat{\\beta}_1,\\widehat{\\beta}_2)$,\n",
    "\\begin{align}\n",
    "\\Sigma = (\\mathbb{E} \\boldsymbol{x}'\\boldsymbol{x})^{-1}\\mathbb{E}(\\epsilon^2)\n",
    "\\end{align}\n",
    "To do so, we use the sample analogue\n",
    "\\begin{align}\n",
    "\\widehat{\\Sigma} = \\left[\\left(\\sum_{j=1}^N\\boldsymbol{x}_j'\\boldsymbol{x}_j\\right)^{-1}\\left(\\sum_{j=1}^N \\widehat{\\epsilon}_j^2\\right)\\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "090e261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance-covariance estimate: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3Ã—3 Matrix{Float64}:\n",
       "  1.83671   0.482321   -0.4893\n",
       "  0.482321  1.9024      0.0306327\n",
       " -0.4893    0.0306327   1.60712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsHat = y - X*betaHat\n",
    "SigHat = inv(X'*X)*(epsHat'*epsHat)\n",
    "\n",
    "println(\"Variance-covariance estimate: \")\n",
    "display(SigHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ede76",
   "metadata": {},
   "source": [
    "Next, we construct the test statistic $\\widehat{t}$ for $H_0:\\beta_1=0$ by dividing the parameter estimate by the square root of $\\Sigma_{22}$ and applying the bias-correction factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d4a3721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic for H0: beta1=0 is -9.75620382539726, with standard error: 0.20118819795337972\n"
     ]
    }
   ],
   "source": [
    "betaHat1 = betaHat[2]\n",
    "stdErr1 = sqrt(SigHat[2,2])/sqrt(N-3)\n",
    "tHat1 = betaHat1/stdErr1;\n",
    "\n",
    "println(\"Test statistic for H0: beta1=0 is \", tHat1, \", with standard error: \", stdErr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ddf3a",
   "metadata": {},
   "source": [
    "We can now compute the $p$ values as the likelihood of obtaining a value at least as large as in absolution value as $\\widehat{t}$.  Precisely, if $f$ denotes the probability density function of a Student's $t$ variable with $3$ degrees of freedom, we want to compute\n",
    "\\begin{align}\n",
    "\\int_{-\\infty}^{-|\\widehat{t}|} f(t)\\; dt + \\int_{|\\widehat{t}|}^\\infty f(t)\\; dt\n",
    "\\end{align}\n",
    "This is equivalent to\n",
    "\\begin{align}\n",
    "F(-|\\widehat{t}|) + (1 - F(|\\widehat{t}|)\n",
    "\\end{align}\n",
    "where $F$ is the cummulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "adb805ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value: 0.002287924020119388\n"
     ]
    }
   ],
   "source": [
    "p = cdf(TDist(3),-abs(tHat1)) + (1-cdf(TDist(3),abs(tHat1)))\n",
    "\n",
    "println(\"p value: \", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b264b",
   "metadata": {},
   "source": [
    "We therefore fail to reject the null at significance level 0.05 with $\\text{N}(0,5)$ errors.  We can also calculate the critical value $c$ such that we require $|\\widehat{t}|\\geq c$ in order to reject.  Since Student's $t$ distributions are symmetric, this is determined by solving\n",
    "\\begin{align}\n",
    "\\int_{-\\infty}^c f(t)\\; dt = 0.025\\ \\ \\ \\iff\\ \\ \\ c=F^{-1}(0.025)\n",
    "\\end{align}\n",
    "To access the inverse CDF in Julia, we can use the quintile command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "20f89934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The critical value for rejecting the null at significance level 0.05 is -3.182446305283709\n"
     ]
    }
   ],
   "source": [
    "critVal = quantile(TDist(3),0.025);\n",
    "println(\"The critical value for rejecting the null at significance level 0.05 is \", critVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e7280",
   "metadata": {},
   "source": [
    "For a further demonstration, let's consider how sample size and error distribution affect the results.  First, we'll consider sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d7346abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing H0: beta<0\n",
      "\n",
      "Sample Size        coeff.     st.dev.     t        se       p\n",
      "-------------------------------------------------------------------\n",
      "Small              -1.96      1.38       -9.76     0.20     0.00\n",
      "Large              -1.67      4.21       -3.92     0.43     0.03"
     ]
    }
   ],
   "source": [
    "Nbig = 100;\n",
    "x1bigSamp = rand(Normal(0,1),Nbig);\n",
    "x2bigSamp = rand(Normal(0,1),Nbig);\n",
    "epsBigSamp = rand(Normal(0,5),Nbig);\n",
    "yBigSamp = alpha .+ beta1*x1bigSamp + beta2*x2bigSamp + epsBigSamp;\n",
    "\n",
    "XbigSamp = [ones(Nbig) x1bigSamp x2bigSamp];\n",
    "\n",
    "betaHatBigSamp = (XbigSamp'*XbigSamp)\\(XbigSamp'*yBigSamp)\n",
    "epsHatBigSamp = yBigSamp - XbigSamp*betaHatBigSamp\n",
    "\n",
    "SigHatBigSamp = inv(XbigSamp'*XbigSamp)*(epsHatBigSamp'*epsHatBigSamp)\n",
    "betaHatBigSamp1 = betaHatBigSamp[2]\n",
    "stdErrBigSamp1 = sqrt(SigHatBigSamp[2,2])/sqrt(Nbig-3)\n",
    "tHatBigSamp1 = betaHatBigSamp1/(stdErrBigSamp1);\n",
    "\n",
    "pBigSamp = cdf(TDist(3),-abs(tHatBigSamp1)) + (1-cdf(TDist(3),abs(tHatBigSamp1)))\n",
    "\n",
    "println(\"Testing H0: beta1=0\")\n",
    "println(\"\")\n",
    "println(\"Sample Size        coeff.     st.dev.     t        se       p\")\n",
    "println(\"-------------------------------------------------------------------\")\n",
    "@printf \"Small              %.2f      %.2f       %.2f     %.2f     %.2f\\n\" betaHat1 sqrt(SigHat[2,2]) tHat1 stdErr1 p\n",
    "@printf \"Large              %.2f      %.2f       %.2f     %.2f     %.2f\" betaHatBigSamp1 sqrt(SigHatBigSamp[2,2]) tHatBigSamp1 stdErrBigSamp1 pBigSamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a350e8f",
   "metadata": {},
   "source": [
    "Running the above code multiple times will generally demonstrate that, with the sample sizes fixed but the sample itself varying, you may end up with drastically different results in your test. As expected, however, the larger sample has a better chance of rejecting the null at the 0.05 significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9950525",
   "metadata": {},
   "source": [
    "Finally, let's see how increasing the variance of the residuals affects the above results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f53d072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing H0: beta<0\n",
      "\n",
      "Sample Size        coeff.     st.dev.     t        se       p\n",
      "-------------------------------------------------------------------\n",
      "Small              -1.96      1.38       -9.76     0.20     0.00\n",
      "Large              -1.63      8.14       -1.38     1.19     0.26"
     ]
    }
   ],
   "source": [
    "sigBig = 7;\n",
    "x1bigSig = rand(Normal(0,1),N);\n",
    "x2bigSig = rand(Normal(0,1),N);\n",
    "epsBigSig = rand(Normal(0,sigBig),N);\n",
    "yBigSig = alpha .+ beta1*x1bigSig + beta2*x2bigSig + epsBigSig;\n",
    "\n",
    "XbigSig = [ones(N) x1bigSig x2bigSig];\n",
    "\n",
    "betaHatBigSig = (XbigSig'*XbigSig)\\(XbigSig'*yBigSig)\n",
    "epsHatBigSig = yBigSig - XbigSig*betaHatBigSig\n",
    "\n",
    "SigHatBigSig = inv(XbigSig'*XbigSig)*(epsHatBigSig'*epsHatBigSig)\n",
    "betaHatBigSig1 = betaHatBigSig[2]\n",
    "stdErrBigSig1 = sqrt(SigHatBigSig[2,2])/sqrt(N-3)\n",
    "tHatBigSig1 = betaHatBigSig1/(stdErrBigSig1);\n",
    "\n",
    "pBigSig = cdf(TDist(3),-abs(tHatBigSig1)) + (1-cdf(TDist(3),abs(tHatBigSig1)))\n",
    "\n",
    "println(\"Testing H0: beta1=0\")\n",
    "println(\"\")\n",
    "println(\"Sample Size        coeff.     st.dev.     t        se       p\")\n",
    "println(\"-------------------------------------------------------------------\")\n",
    "@printf \"Small              %.2f      %.2f       %.2f     %.2f     %.2f\\n\" betaHat1 sqrt(SigHat[2,2]) tHat1 stdErr1 p\n",
    "@printf \"Large              %.2f      %.2f       %.2f     %.2f     %.2f\" betaHatBigSig1 sqrt(SigHatBigSig[2,2]) tHatBigSig1 stdErrBigSig1 pBigSig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013bcd4b",
   "metadata": {},
   "source": [
    "Higher error variance generally makes it harder for the test to reject the null, although it still manages to do so for some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2527e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
